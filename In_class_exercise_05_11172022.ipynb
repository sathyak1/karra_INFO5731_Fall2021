{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/17/2022)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f59b9c523bfa>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_data = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['reviews'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting-room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0  a stirring , funny and finally transporting re...         1\n",
       "1  apparently reassembled from the cutting-room f...         0\n",
       "2  they presume their audience wo n't sit still f...         0\n",
       "3  this is a visually stunning rumination on love...         1\n",
       "4  jonathan parker 's bartleby should have been t...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('stsa-train.txt',sep = 'delimiter=',header= None,names=['reviews'])\n",
    "train_data[['sentiment','reviews']] = train_data['reviews'].str.split(\" \", 1, expand=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-78bf0d440991>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_data = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['reviews'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is one of polanski 's best films .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0     no movement , no yuks , not much of anything .         0\n",
       "1  a gob of drivel so sickly sweet , even the eag...         0\n",
       "2  gangs of new york is an unapologetic mess , wh...         0\n",
       "3  we never really feel involved with the story ,...         0\n",
       "4            this is one of polanski 's best films .         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('stsa-test.txt',sep = 'delimiter=',header= None,names=['reviews'])\n",
    "test_data[['sentiment','reviews']] = test_data['reviews'].str.split(\" \", 1, expand=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saisrikarvattem/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/saisrikarvattem/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopword=nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl= WordNetLemmatizer()\n",
    "\n",
    "def clean(review):\n",
    "    review =\"\".join([word.lower() for word in review if word not in string.punctuation])\n",
    "    review = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", review)\n",
    "    tokens = re.split('\\W+',review)\n",
    "    review = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 13343)\n",
      "(1821, 13343)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer = clean)\n",
    "X_tfidf = tfidf_vect.fit_transform(train_data['reviews'])\n",
    "print(X_tfidf.shape)\n",
    "X_tfidf_df=pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns=tfidf_vect.get_feature_names()\n",
    "X_test_tfidf = tfidf_vect.transform(test_data['reviews'])\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7955202312138728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       671\n",
      "           1       0.76      0.88      0.82       713\n",
      "\n",
      "    accuracy                           0.80      1384\n",
      "   macro avg       0.80      0.79      0.79      1384\n",
      "weighted avg       0.80      0.80      0.79      1384\n",
      "\n",
      "MultinominalNB score:  0.7247054530288813\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_tfidf_df, train_data['sentiment'].values,test_size=0.2, random_state=42)\n",
    "model_mnb = mnb.fit(x_train,y_train)\n",
    "y_pred_mnb = model_mnb.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_mnb,y_test))\n",
    "print(classification_report(y_test,y_pred_mnb))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mnb, x_test, y_test, cv=10)\n",
    "print(\"MultinominalNB score: \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.791907514450867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       671\n",
      "           1       0.78      0.83      0.80       713\n",
      "\n",
      "    accuracy                           0.79      1384\n",
      "   macro avg       0.79      0.79      0.79      1384\n",
      "weighted avg       0.79      0.79      0.79      1384\n",
      "\n",
      "SVM score: 0.7348034615785632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "svm = LinearSVC()\n",
    "model_svm = svm.fit(x_train,y_train)\n",
    "y_pred_svm = model_svm.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_svm,y_test))\n",
    "print(classification_report(y_test,y_pred_svm))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svm, x_test, y_test, cv=10)\n",
    "print(\"SVM score:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.740606936416185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       671\n",
      "           1       0.74      0.77      0.75       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.74      0.74      0.74      1384\n",
      "weighted avg       0.74      0.74      0.74      1384\n",
      "\n",
      "KNN score: 0.6675737670732979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "model_knn = knn.fit(x_train,y_train)\n",
    "y_pred_knn = model_knn.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_knn,y_test))\n",
    "print(classification_report(y_test,y_pred_knn))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(knn, x_test, y_test, cv=10)\n",
    "print(\"KNN score:\",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6632947976878613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64       671\n",
      "           1       0.66      0.71      0.69       713\n",
      "\n",
      "    accuracy                           0.66      1384\n",
      "   macro avg       0.66      0.66      0.66      1384\n",
      "weighted avg       0.66      0.66      0.66      1384\n",
      "\n",
      "Decision tree score: 0.6177875091231363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "model_dt = dt.fit(x_train,y_train)\n",
    "y_pred_dt = model_dt.predict(x_test)\n",
    "print('Accuracy %s' % accuracy_score(y_pred_dt,y_test))\n",
    "print(classification_report(y_test,y_pred_dt))\n",
    "scores = cross_val_score(dt, x_test, y_test, cv=10)\n",
    "print(\"Decision tree score:\",scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saisrikarvattem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/saisrikarvattem/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "<ipython-input-22-62b26541066d>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Reviews'] = df['Reviews'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>feel lucky found used phone u used hard phone ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone nice grade pantach revue clean set ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>work good go slow sometimes good phone love</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>great phone replace lost phone thing volume bu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  feel lucky found used phone u used hard phone ...           1.0  \n",
       "1       4  nice phone nice grade pantach revue clean set ...           0.0  \n",
       "2       5                                            pleased           0.0  \n",
       "3       4        work good go slow sometimes good phone love           0.0  \n",
       "4       4  great phone replace lost phone thing volume bu...           0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "from textblob import Word\n",
    "nltk.download('wordnet')\n",
    "\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "df['Reviews'] = df['Reviews'].str.replace('[^\\w\\s]','')\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 163542,\n",
       "         2: 181149,\n",
       "         3: 17213,\n",
       "         6: 2551,\n",
       "         4: 15841,\n",
       "         0: 11589,\n",
       "         8: 6622,\n",
       "         7: 9221,\n",
       "         1: 6112})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
    "names= tfidf_vect.get_feature_names()\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 9,init='k-means++',max_iter=10000, random_state=50)\n",
    "model.fit(tfidf_vects)\n",
    "from collections import Counter\n",
    "Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1\n",
      "Top Words: ['excellent', 'product', 'phone', 'condition', 'recommend', 'good', 'seller']\n",
      "Cluster 2\n",
      "Top Words: ['nice', 'phone', 'price', 'product', 'good', 'love', 'work']\n",
      "Cluster 3\n",
      "Top Words: ['work', 'perfect', 'good', 'product', 'ok', 'like', 'excelent']\n",
      "Cluster 4\n",
      "Top Words: ['good', 'phone', 'product', 'price', 'work', 'far', 'thanks']\n",
      "Cluster 5\n",
      "Top Words: ['great', 'phone', 'work', 'product', 'price', 'condition', 'buy']\n",
      "Cluster 6\n",
      "Top Words: ['phone', 'great', 'work', 'good', 'one', 'like', 'battery']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.30950605e-06, 5.51973859e-06, 4.02105443e-06, ...,\n",
       "        5.41396440e-06, 1.94155592e-06, 4.31972939e-06],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = 7\n",
    "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for cluster_num in range(6):\n",
    "    key_features = [names[i] for i in centroids[cluster_num, :top_words]]\n",
    "    print('Cluster '+str(cluster_num+1))\n",
    "    print('Top Words:', key_features)\n",
    "    \n",
    "cluster_center=model.cluster_centers_\n",
    "cluster_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write you answer here. (No code needed)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
